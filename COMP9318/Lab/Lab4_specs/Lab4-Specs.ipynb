{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9318 Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. This note book contains instructions for **COMP9318-Lab4**.\n",
    "\n",
    "* You are required to complete your implementation in a file `submission.py` provided along with this notebook.\n",
    "\n",
    "* You are not allowed to print out unnecessary stuff. We will not consider any output printed out on the screen. All results should be returned in appropriate data structures via corresponding functions.\n",
    "\n",
    "* You can submit your implementation for **Lab4** via following link: https://kg.cse.unsw.edu.au/submit/ .\n",
    "\n",
    "* For each question, we have provided you with detailed instructions along with question headings. In case of any problem, you can post your query @ Piazza.\n",
    "\n",
    "* You are allowed to add other functions and/or import modules (you may have to in this lab), but you are not allowed to define global variables. **Only functions are allowed** in `submission.py`. \n",
    "\n",
    "* You should not import unnecessary modules/libraries, failing to import such modules at test time will lead to errors.\n",
    "\n",
    "* We will provide immediate feedback on your submission. You can access your scores using the online submission portal on the same day. \n",
    "\n",
    "* For **Final Evaluation** we will be using a different dataset, so your final scores may vary.  \n",
    "\n",
    "* You are allowed to submit as many times as you want before the deadline, but **ONLY the latest version will be kept and marked**.\n",
    "\n",
    "* Submission deadline for this assignment is **23:59:59 on 16th April, 2019**. We will **not** accept any late submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-1: Text Classification using Multinomial Naive Bayes\n",
    "\n",
    "You are required to implement a multinomial naive bayes classifier to predict spam SMS.\n",
    "\n",
    "The training data is a set of SMS categoried into `spam` and `ham`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv('./asset/data.txt', sep='\\t')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement a unigram model, first we tokenize the text. We use the count corresponding to each token (word) in the SMS as its feature (i.e., bag of words). We store the features and catrgorical information for each SMS in a `dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssss Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "ssss Ok lar... Joking wif u oni...\n",
      "ssss Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "ssss U dun say so early hor... U c already then say...\n",
      "ssss Nah I don't think he goes to usf, he lives around here though\n",
      "ssss FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\n",
      "ssss I am not spam\n",
      "0.5\n",
      "0.4685534591194969\n",
      "50\n",
      "99\n",
      "60\n",
      "[0, 0, 0, 0]\n",
      "[1, 0, 0, 0]\n",
      "0.23427672955974846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "############### Question 1 #################\n",
    "\n",
    "sms = 'I am not spam'\n",
    "raw_data = pd.read_csv('./asset/data.txt', sep='\\t')\n",
    "raw_data.head()\n",
    "\n",
    "def tokenize(sms):\n",
    "    return sms.split(' ')\n",
    "\n",
    "def get_freq_of_tokens(sms):\n",
    "    tokens = {}\n",
    "    for token in tokenize(sms):\n",
    "        if token not in tokens:\n",
    "            tokens[token] = 1\n",
    "        else:\n",
    "            tokens[token] += 1\n",
    "\n",
    "    return tokens\n",
    "\n",
    "training_data = []\n",
    "for index in range(len(raw_data)):\n",
    "    training_data.append((get_freq_of_tokens(raw_data.iloc[index].text), raw_data.iloc[index].category))\n",
    "\n",
    "\n",
    "\n",
    "sms = tokenize(sms)\n",
    "\n",
    "c_ham=0\n",
    "c_spam=0\n",
    "L_spam = 0\n",
    "L_count = []\n",
    "L_ham = 0\n",
    "spam_list = [0]*len(sms)\n",
    "ham_list = [0]*len(sms)\n",
    "for tup in training_data:\n",
    "    if tup[1]=='ham':\n",
    "        c_ham=c_ham+1\n",
    "\n",
    "        for key,value in tup[0].items():\n",
    "            L_ham += tup[0][key]\n",
    "            for i in range(len(sms)):\n",
    "                if sms[i] == key:\n",
    "                    ham_list[i] += value\n",
    "            if key not in L_count:\n",
    "                L_count.append(key)\n",
    "    else:\n",
    "        c_spam=c_spam+1\n",
    "        for key,value in tup[0].items():\n",
    "            L_spam += tup[0][key]\n",
    "            for j in range(len(sms)):\n",
    "                if sms[j] == key:\n",
    "                    spam_list[j] += value\n",
    "            if key not in L_count:\n",
    "                L_count.append(key)\n",
    "Pcj = c_spam/c_ham\n",
    "number_of_vocab = len(L_count)\n",
    "print(Pcj)\n",
    "\n",
    "for i in range(len(spam_list)):\n",
    "    if spam_list[i] == 0 and ham_list[i] == 0:\n",
    "        continue\n",
    "    else:\n",
    "        P_ham = (ham_list[i]+1)/(L_ham + number_of_vocab)\n",
    "        P_spam = (spam_list[i]+1)/(L_spam + number_of_vocab)\n",
    "        answer = P_spam/P_ham\n",
    "        print(answer)\n",
    "        Pcj *= answer\n",
    "\n",
    "\n",
    "\n",
    "print(L_ham)\n",
    "print(number_of_vocab)\n",
    "print(L_spam)\n",
    "print(spam_list)\n",
    "print(ham_list)\n",
    "print(Pcj)\n",
    "\n",
    "\n",
    "\n",
    "#print(multinomial_nb(training_data, tokenize(sms))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, you need to **implement** a multinomial naive bayes classifier (i.e., `multinomial_nb()` in the file: `submission.py`) with add-1 smoothing. The input arguments of `multinomial_nb()` are:\n",
    "* `training_data`: pre-processed data stored as a `dictionary`\n",
    "* `sms`: test-sms (i.e., a list of tokens) that you need to categorize as `spam` and/or `ham`\n",
    "\n",
    "The return value of `multinomial_nb()` should be the **ratio** of the probability of sms is spam and the probability of sms is ham. A return value larger than 1 implies the `sms` is spam and vice versa.\n",
    "\n",
    "For example, a sample output is shown in the cell given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Test Environment\n",
    "\n",
    "For testing, we have pre-installed the requisite modules and/or libraries in the testing environment. You are only allowed to use following libraries:\n",
    "* python: 3.6.5\n",
    "* pandas: 0.19.2\n",
    "\n",
    "NOTE: You are required to implement the classifier by yourself. You are not allowed to import **sklearn** and/or any other library in Lab4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6d0570343a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I am not spam'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultinomial_nb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-292f4cfb8d0c>\u001b[0m in \u001b[0;36mmultinomial_nb\u001b[0;34m(training_data, sms)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultinomial_nb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mnSmsLen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mlstSpam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnIndex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnSmsLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-292f4cfb8d0c>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(sms)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m################# Question 1 #################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_freq_of_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "## How we test your implementation...\n",
    "# import submission_ans as submission\n",
    "\n",
    "# sms = 'I am not spam'\n",
    "# print(submission.multinomial_nb(training_data, tokenize(sms)))\n",
    "\n",
    "\n",
    "\n",
    "sms = 'I am not spam'\n",
    "print(multinomial_nb(training_data, tokenize(sms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
